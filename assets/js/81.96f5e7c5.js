(window.webpackJsonp=window.webpackJsonp||[]).push([[81],{580:function(t,s,n){"use strict";n.r(s);var a=n(19),e=Object(a.a)({},(function(){var t=this,s=t.$createElement,n=t._self._c||s;return n("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[n("h2",{attrs:{id:"前言"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#前言"}},[t._v("#")]),t._v(" 前言")]),t._v(" "),n("p",[t._v("原型模式属于创建型模式，这个类型的设计模式是将 对象的创建和使用解耦了，花式的去创建对象。")]),t._v(" "),n("h2",{attrs:{id:"原型模式"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#原型模式"}},[t._v("#")]),t._v(" 原型模式")]),t._v(" "),n("p",[t._v("应用场景：克隆已有对象，分为浅克隆、深克隆。意在减少创建重复对象的成本，有时你要创建的对象可能与已创建对象仅有细微差别，这时候你可以直接克隆已存在的对象，然后再变更你克隆的对象的数据，最终快速达到你预期的结果。")]),t._v(" "),n("p",[t._v("理解：复杂对象的创建和使用解耦了，通过对象克隆可以很简单的获得一个一摸一样的对象，内部还是进行了对象创建的操作。克隆对象的操作分为浅克隆和深克隆，浅克隆操作比较简单，而深克隆相对来说复杂一些，通过以上的代码示例可以看出来。浅克隆只能克隆一些皮毛，而且有时你修改了浅克隆后的对象会影响之前被你克隆的对象，这样的副作用很不友好，所以一般都使用深克隆。当然实际开发中一个复杂的对象会比代码示例中复杂几倍、十几倍、几十倍等等，所以一般都会采取三种方式：一、"),n("a",{attrs:{href:"https://juejin.cn/post/6844903929705136141",target:"_blank",rel:"noopener noreferrer"}},[t._v("通过js动态语言的特性以及递归循环判断类型的方式来进行深克隆"),n("OutboundLink")],1),t._v("。二、通过 JSON.parse(JSON.stringify(obj))的方式，这种方式会将对象序列化为json字符串然后再反序列化为js对象，不过这种方式只能克隆数据，遇到复杂的就会有副作用，比如无法克隆对象的函数。三、采用面向对象的方式针对性的去硬编码完成这个复杂对象的克隆操作，虽然很标准，但是用在动态语言上就显得不那么灵活了，比如下面的代码示例。")]),t._v(" "),n("div",{staticClass:"language-ts extra-class"},[n("pre",{pre:!0,attrs:{class:"language-ts"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("namespace")]),t._v(" creative_mode_04 "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 产品类")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("class")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Student")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n\n        name"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("string")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("''")]),t._v("\n        age"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("string")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("''")]),t._v("\n        height"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("string")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("''")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// classNum: string = ''")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// levelNum: string = ''")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// teacher: string = ''")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// father: string = ''")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// mother: string = ''")]),t._v("\n        dog"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("?")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" Dog \n        cat"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("?")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" Cat\n    "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("class")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Dog")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        dogName"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("string")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("''")]),t._v("\n        dogIQ"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("?")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("number")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("class")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Cat")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        catName"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("string")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("''")]),t._v("\n        catIQ"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("?")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("number")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 浅克隆、深克隆的接口")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("interface")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("ICloneStudentable")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("clone")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("student"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" Student"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" Student\n        "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("deepClone")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("student"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" Student"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" Student\n    "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 克隆机器")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("class")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("CloneMachine")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("implements")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("ICloneStudentable")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 浅克隆")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("clone")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("student"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" Student"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" Student "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!")]),t._v("student "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("||")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("student "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("instanceof")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Student")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n                "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("throw")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Error")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"param is null or not Student instance."')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n            "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("const")]),t._v(" newStudent "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Student")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n            newStudent"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("name "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" student"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("name\n            newStudent"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("age "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" student"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("age\n            newStudent"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("height "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" student"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("height\n            newStudent"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("dog "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" student"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("dog\n            newStudent"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("cat "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" student"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("cat\n\n            "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" newStudent\n        "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 深克隆")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("deepClone")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("student"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" Student"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" Student "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!")]),t._v("student "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("||")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("student "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("instanceof")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Student")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n                "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("throw")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Error")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"param is null or not Student instance."')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n            "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("const")]),t._v(" newStudent "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Student")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n            newStudent"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("name "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" student"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("name\n            newStudent"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("age "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" student"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("age\n            newStudent"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("height "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" student"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("height\n            newStudent"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("dog "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Dog")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n            newStudent"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("dog"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("dogName "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" student"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("dog"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("?.")]),t._v("dogName "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("||")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("''")]),t._v("\n            newStudent"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("dog"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("dogIQ "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" student"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("dog"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("?.")]),t._v("dogIQ\n            newStudent"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("cat "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Cat")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n            newStudent"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("cat"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("catName "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" student"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("cat"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("?.")]),t._v("catName "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("||")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("''")]),t._v("\n            newStudent"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("cat"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("catIQ "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" student"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("cat"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("?.")]),t._v("catIQ\n\n            "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// const newStudent = JSON.parse(JSON.stringify(student))")]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" newStudent\n        "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 复杂对象初始化")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("const")]),t._v(" student1 "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Student")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    student1"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("name "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'马文'")]),t._v("\n    student1"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("age "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'8岁'")]),t._v("\n    student1"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("height "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'120cm'")]),t._v("\n    student1"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("dog "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Dog")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    student1"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("dog"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("dogName "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'黄元帅'")]),t._v("\n    student1"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("dog"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("dogIQ "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("20")]),t._v("\n    student1"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("cat "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Cat")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    student1"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("cat"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("catName "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'毛牙'")]),t._v("\n    student1"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("cat"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("catIQ "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("12")]),t._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 使用")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("const")]),t._v(" cloneMachine "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("CloneMachine")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 浅克隆")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("const")]),t._v(" newStudent1 "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" cloneMachine"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("clone")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("student1"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    newStudent1"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("name "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'马子明'")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 部分修改")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("console")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("log")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'newStudent1 === student1 ===>>> '")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" newStudent1 "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("===")]),t._v(" student1"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// false")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("console")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("log")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'newStudent1.dog === student1.dog ===>>> '")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" newStudent1"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("dog "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("===")]),t._v(" student1"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("dog"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// true")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("console")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("log")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'newStudent1.cat === student1.cat ===>>> '")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" newStudent1"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("cat "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("===")]),t._v(" student1"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("cat"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// true")]),t._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 深克隆")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("const")]),t._v(" newStudent2 "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" cloneMachine"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("deepClone")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("student1"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    newStudent2"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("name "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'江钰'")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 部分修改")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("console")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("log")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'newStudent2 === student1 ===>>> '")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" newStudent2 "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("===")]),t._v(" student1"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// false")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("console")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("log")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'newStudent2.dog === student1.dog ===>>> '")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" newStudent2"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("dog "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("===")]),t._v(" student1"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("dog"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// false")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("console")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("log")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'newStudent2.cat === student1.cat ===>>> '")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" newStudent2"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("cat "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("===")]),t._v(" student1"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("cat"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// false")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])])])}),[],!1,null,null,null);s.default=e.exports}}]);